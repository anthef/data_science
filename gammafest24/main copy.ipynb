{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "from imutils.contours import sort_contours\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    dimensions = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                dimensions.append(img.shape[:2])  # Append the (height, width)\n",
    "    return images, dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, dimensions = load_images_from_folder(\"Train\")\n",
    "test_images, test_dimensions = load_images_from_folder(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension Statistics:\n",
      "Average Height: 859.32\n",
      "Average Width: 747.52\n",
      "Median Height: 944.5\n",
      "Median Width: 810.0\n",
      "Top 3 Most Common Heights: [(961, 14), (962, 13), (965, 9)]\n",
      "Top 3 Most Common Widths: [(813, 22), (819, 14), (816, 11)]\n"
     ]
    }
   ],
   "source": [
    "def analyze_image_dimensions(dimensions):\n",
    "    heights = [dim[0] for dim in dimensions]\n",
    "    widths = [dim[1] for dim in dimensions]\n",
    "\n",
    "    average_height = np.mean(heights)\n",
    "    average_width = np.mean(widths)\n",
    "    median_height = np.median(heights)\n",
    "    median_width = np.median(widths)\n",
    "\n",
    "    height_freq = Counter(heights)\n",
    "    width_freq = Counter(widths)\n",
    "\n",
    "    most_common_heights = height_freq.most_common(3)\n",
    "    most_common_widths = width_freq.most_common(3)\n",
    "\n",
    "    return {\n",
    "        \"average_height\": average_height,\n",
    "        \"average_width\": average_width,\n",
    "        \"median_height\": median_height,\n",
    "        \"median_width\": median_width,\n",
    "        \"most_common_heights\": most_common_heights,\n",
    "        \"most_common_widths\": most_common_widths\n",
    "    }\n",
    "\n",
    "stats = analyze_image_dimensions(dimensions)\n",
    "\n",
    "print(\"Image Dimension Statistics:\")\n",
    "print(f\"Average Height: {stats['average_height']:.2f}\")\n",
    "print(f\"Average Width: {stats['average_width']:.2f}\")\n",
    "print(f\"Median Height: {stats['median_height']}\")\n",
    "print(f\"Median Width: {stats['median_width']}\")\n",
    "print(\"Top 3 Most Common Heights:\", stats['most_common_heights'])\n",
    "print(\"Top 3 Most Common Widths:\", stats['most_common_widths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 961\n",
    "width = 813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, target_size=(961, 813)):\n",
    "    resized_images = []\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        original_size = image.shape[:2]\n",
    "        if original_size[0] < target_size[0] or original_size[1] < target_size[1]:\n",
    "            interpolation = cv2.INTER_CUBIC\n",
    "        else:\n",
    "            interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "        resized_image = cv2.resize(image, (target_size[1], target_size[0]), interpolation=interpolation)\n",
    "        # cv2.imwrite(f\"resized_rotated_train/{i}.jpg\", resized_image)\n",
    "        resized_images.append(resized_image)\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train = resize_images(images)\n",
    "resized_test = resize_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing Image (Applying CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_images(images_path):\n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Read image\n",
    "            image_path = os.path.join(images_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(image, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\n",
    "            enhanced_image = clahe.apply(image)\n",
    "            cv2.imwrite(image_path, enhanced_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"train_enhanced/train_enhanced\"\n",
    "\n",
    "# Preprocess images in the folder\n",
    "enhance_images(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(images_path):\n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Read image\n",
    "            image_path = os.path.join(images_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            # Convert image to grayscale\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Apply Otsu's thresholding\n",
    "            _, thresh = cv2.threshold(gray_image, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
    "            enhanced_image = clahe.apply(gray_image)\n",
    "            # Overwrite the enhanced image\n",
    "            cv2.imwrite(image_path, enhanced_image)\n",
    "\n",
    "# Path to the folder containing images\n",
    "images_folder = \"train_enhanced/train_enhanced\"\n",
    "\n",
    "# Preprocess images in the folder\n",
    "enhance_image(images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_train = enhance_image(resized_train)\n",
    "# cv2.imwrite(\"A.jpg\", enhanced_train[48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(images):\n",
    "    cropped_images = []\n",
    "    for i in range(len(images)):\n",
    "        x = 813-240\n",
    "        y = 30\n",
    "        cropped_images.append(images[i][y:y+height, x:x+width])\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_train = crop_image(enhanced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect(self, c):\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    "        elif len(approx) == 4:\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "            shape = \"square\" if 0.95 <= ar <= 1.05 else \"rectangle\"\n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    "        return shape\n",
    "\n",
    "sd = ShapeDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rectangles(image):\n",
    "    thresh = cv2.threshold(image, 0, 255,\n",
    "        cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    specified_rectangles = []\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] != 0:  # To avoid division by zero\n",
    "            cX = int((M[\"m10\"] / M[\"m00\"]))\n",
    "            cY = int((M[\"m01\"] / M[\"m00\"]))\n",
    "            shape = sd.detect(c)\n",
    "            if shape == \"rectangle\":\n",
    "                # Retrieve the bounding box to check dimensions\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                # Check if the rectangle meets the dimension criteria\n",
    "                if 40 <= w <= 275 and 225 <= h <= 375:\n",
    "                    cropped_image = image[y:y+h, x:x+w]\n",
    "                    specified_rectangles.append(cropped_image)\n",
    "    return specified_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 68, 84, 107, 206, 212, 221, 241, 253, 269, 296, 395, 421, 429, 467]\n"
     ]
    }
   ],
   "source": [
    "specified_rectangles = []\n",
    "need_rotate = []\n",
    "for i in range(len(cropped_train)):\n",
    "    specified_rectangles.append(get_rectangles(cropped_train[i]))\n",
    "    if len(specified_rectangles[i]) > 0:\n",
    "        for j in range(len(specified_rectangles[i])):\n",
    "            cv2.imwrite(f\"cropped_rectangle/{i}_{j}.jpg\", specified_rectangles[i][j])\n",
    "    else:\n",
    "        need_rotate.append(i)\n",
    "print(need_rotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
